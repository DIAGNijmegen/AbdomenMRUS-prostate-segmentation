# Prostate Segmentation in MRI Training Steps

This document aims to make the development steps of this prostate segmentation algorithm transparent. Except for a handful of private training cases, all resources and steps to reproduce this algorithm are provided.

⚠️ Note: we provided the commands as if you're directly running Docker containers. In fact, we used a distributed system with SLURM to train models and perform inference. Please report any bugs you encounter [here](https://github.com/DIAGNijmegen/AbdomenMRUS-prostate-segmentation/issues).


## Preparation
The data preparation steps require `picai_prep` to be installed:

```
pip install picai_prep==2.0.1
```


### Folder Structure
We define three main folders that must be prepared apriori:

- `/input/` contains the dataset (after following the [Data Preparation](#Data-Preparation) steps below).
  - `/input/images/` contains the imaging files.
  - `/input/labels/` contains the annotations.
- `/workdir/` stores intermediate results, such as preprocessed images and annotations.
  - `/workdir/results/[model name]/` stores model checkpoints/weights during training (enables the ability to pause/resume training).
- `/output/` stores output, such as trained model weights and prostate segmentations.

Most of the cases used to train this model are publicly available. The ProstateX cases can be retrieved [here][PROSTATEx_masks], and the Prostate158 cases can be retrieved [here](https://prostate158.grand-challenge.org/).

Note: on our system, `/workdir/` is located at `/media/pelvis/projects/joeran/picai/workdir`.


### Data Preparation
We follow the [`nnU-Net Raw Data Archive`][nnunet_raw_data_format] format to prepare our dataset for usage. For this, you can use the [`picai_prep`][picai_prep] module. Please read the instructions [provided here](https://github.com/DIAGNijmegen/picai_prep#mha--nnunet) for instructions on preparing a [`DICOM Archive`][what_is_dicom_archive] or [`MHA Archive`][what_is_mha_archive] into the [`nnU-Net Raw Data Archive`][nnunet_raw_data_format] format. 

In preparation of this project, we retrieved the zonal prostate segmentations from [R. Cuocolo, _et al._][PROSTATEx_masks], and converted the annotations to the _RAI image orientation_ (instead of _RPI_). Additionally, we converted the [ProstateX DICOM Archive](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=23691656) into the [`MHA Archive`][what_is_mha_archive] format using `picai_prep`. Depending on how the images are sourced, the [whole_gland_seg_archive.py](training/whole_gland_seg_archive.py) script needs to be adapted accordingly.

After this preparation, we generated the `mha2nnunet_settings.json` using:

```bash
python training/whole_gland_seg_archive.py
```

Subsequently, we converted the images and annotations to the [`nnU-Net Raw Data Archive`][nnunet_raw_data_format] format using:

```bash
python training/prepare_data.py
```


## Training with nnU-Net
The nnU-Net framework [[1]](#1) provides a performant framework for medical image segmentation. We chose to replace the default Cross-Entropy + soft Dice loss for Cross-Entropy + Focal loss. We believe this makes the segmentation model more robust[[2]](#2).


### nnU-Net - Docker Setup
To run nnU-Net commands, we used the Docker specified in [`picai_baseline` → `Dockers/nnunet/`](https://github.com/DIAGNijmegen/picai_baseline/tree/main/src/picai_baseline/Dockers/nnunet). This is a wrapper around nnU-Net, and facilitates training in a Docker container on a distributed system. The pre-built Docker container can be pulled from [Docker Hub][picai_nnunet_docker]:

```
docker pull joeranbosma/picai_nnunet:1.7.0-customized-v1.4
```


### nnU-Net - Cross-Validation Splits
We used the cross-validation splits automatically generated by nnU-Net.


### nnU-Net - Training
For general documentation on how to train nnU-Net models, please check the [official documentation](https://github.com/MIC-DKFZ/nnUNet#usage). We use the nnU-Net wrapper to orchestrate the `nnUNet_plan_and_preprocess` and `nnUNet_train` steps. We swapped out Cross-Entropy + soft Dice loss for Cross-Entropy + Focal loss.

Running the first fold will start with preprocessing the raw images. After preprocessing is done, it will automatically start training.

```bash
docker run --cpus=8 --memory=32gb --shm-size=32gb --gpus='"device=0"' -it --rm \
    -v /path/to/workdir:/workdir \
    joeranbosma/picai_nnunet:latest nnunet plan_train \
    Task2202_prostate_segmentation /workdir \
    --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints --fold 0
```

After preprocessing is done, the other folds can be run sequentially or in parallel:

```bash
docker run --cpus=8 --memory=32gb --shm-size=32gb --gpus='"device=0"' -it --rm -v /path/to/workdir:/workdir joeranbosma/picai_nnunet:latest nnunet plan_train Task2202_prostate_segmentation /workdir --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints --fold 1
docker run --cpus=8 --memory=32gb --shm-size=32gb --gpus='"device=0"' -it --rm -v /path/to/workdir:/workdir joeranbosma/picai_nnunet:latest nnunet plan_train Task2202_prostate_segmentation /workdir --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints --fold 2
docker run --cpus=8 --memory=32gb --shm-size=32gb --gpus='"device=0"' -it --rm -v /path/to/workdir:/workdir joeranbosma/picai_nnunet:latest nnunet plan_train Task2202_prostate_segmentation /workdir --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints --fold 3
docker run --cpus=8 --memory=32gb --shm-size=32gb --gpus='"device=0"' -it --rm -v /path/to/workdir:/workdir joeranbosma/picai_nnunet:latest nnunet plan_train Task2202_prostate_segmentation /workdir --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints --fold 4
```

Notes: ran in our environment with 28 GB RAM, 8 CPUs, 1 GPU with 8 GB VRAM. Takes about 3 days per fold on an RTX 2080 Ti.

### nnU-Net - Inference
After training nnU-Net, we can perform inference using nnU-Net's default parameters.

First, let nnU-Net determine the postprocessing steps:

```bash
docker run --gpus='"device=0"' \
    -v /path/to/workdir:/workdir \
    joeranbosma/picai_nnunet:latest nnunet find_best_configuration \
    Task2202_prostate_segmentation /workdir \
    --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints \
    --networks 3d_fullres
```

Then, you can segment bpMRI cases that are converted to the [`nnU-Net Raw Data Archive`][nnunet_raw_data_format] format using:

```bash
docker run --gpus='"device=0"' \
    -v /path/to/workdir:/workdir \
    -v /path/to/output:/output \
    joeranbosma/picai_nnunet nnunet predict Task2202_prostate_segmentation \
    --trainer nnUNetTrainerV2_Loss_FL_and_CE_checkpoints \
    --folds 0,1,2,3,4 \
    --results /workdir/results \
    --input /workdir/nnUNet_raw_data/Task2202_prostate_segmentation/images_picai_pubtrain \
    --output /output/prostate_segmentation
```

To segment the [PI-CAI: Public Training and Development Dataset](https://pi-cai.grand-challenge.org/DATA/), we generated the `mha2nnunet_settings.json` using:

```bash
python training/whole_gland_seg_archive_inference.py
```

And subsequently converted to the [`nnU-Net Raw Data Archive`][nnunet_raw_data_format] format using:

```bash
python -m picai_prep mha2nnunet \
    --input /media/pelvis/data/prostate-MRI/picai/ \
    --output /media/pelvis/projects/joeran/picai/workdir/nnUNet_raw_data \
    --out_dir_scans images_picai_pubtrain \
    --json /media/pelvis/projects/joeran/picai/workdir/mha2nnunet_settings/Task2202_prostate_segmentation_picai_inference.json
```

### nnU-Net - Evaluation
We relied on nnU-Net's default evaluation. After determining the postprocessing steps, nnU-Net stores its cross-validation results in `/workdir/results/nnUNet/3d_fullres/Task2202_prostate_segmentation/nnUNetTrainerV2_Loss_FL_and_CE_checkpoints__nnUNetPlansv2.1/cv_niftis_postprocessed/summary.json`. We collected these metrics and calculated the statistics using:

```bash
python training/read_performance_nnunet.py
```

### nnU-Net - Grand Challenge Algorithm Docker Container
The root of this repository contains all resources necessary to build the Docker container for inference. In fact, the [algorithm on grand-challenge.org](https://grand-challenge.org/algorithms/prostate-segmentation/) was built by [linking this repository to grand-challenge.org](https://grand-challenge.org/documentation/linking-a-github-repository-to-your-algorithm/).

## References
<a id="1" href="https://www.nature.com/articles/s41592-020-01008-z">[1]</a> 
Fabian Isensee, Paul F. Jaeger, Simon A. A. Kohl, Jens Petersen and Klaus H. Maier-Hein. "nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation". Nature Methods 18.2 (2021): 203-211.

<a id="2" href="#">[2]</a> 
Joeran Bosma, Natalia Alves and Henkjan Huisman. "Performant and Reproducible Deep Learning-Based Cancer Detection Models for Medical Imaging". _Under Review_.


[picai_nnunet_docker]: https://hub.docker.com/r/joeranbosma/picai_nnunet
[picai_prep]: https://github.com/DIAGNijmegen/picai_prep
[nnunet_raw_data_format]: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_conversion.md
[what_is_dicom_archive]: https://github.com/DIAGNijmegen/picai_prep#what-is-a-dicom-archive
[what_is_mha_archive]: https://github.com/DIAGNijmegen/picai_prep#what-is-an-mha-archive
[PROSTATEx_masks]: https://github.com/rcuocolo/PROSTATEx_masks/
